            +--------------------+
            |        CS 140      |
            | PROJECT 1: THREADS |
            |   DESIGN DOCUMENT  |
            +--------------------+
                   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Woo Hyun Jin <whjin@stanford.edu>
Joon Yeong Kim <kim64@stanford.edu>
Anand Madhavan <manand@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

***************************************************************************
*****
static struct list wait_semas;

A sorted list of semaphores for threads put to sleep for timer interrupt
to check for threads that need to wake up.

*****
static struct lock wait_semas_lock;

A lock for wait_semas list access to synchronize insertion into the list.

*****
struct sleep_sema_elem
  {
    struct list_elem elem;
    int wakeup_tick;		/* wake me up when this tick occurs */
    struct semaphore sema;  	/* semaphore to signal the thread to 
    	   	     		   wake up at wakeup_tick */
  };

A struct exclusively for semaphores used for putting threads to sleep.
Contains a semaphore element and the time (tick) it is supposed to 
wake up.
***************************************************************************

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

***************************************************************************
In our design, we start with a list of semaphores, wait_semas, for threads 
put to sleep with its wake up time (tick) recorded.

When timer_sleep is called, a semaphore is created and the tick it is 
supposed to wake up at is recorded with the semaphore and combined as 
a sleep_sema elem. 

The element is inserted into wait_semas ordered by increasing wakeup_tick
so that the timer interrupt can only check the front of the list if no
thread is available to wake up.
***************************************************************************


>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

***************************************************************************
Our initial design for the sleep_sema_elem struct recorded the number of 
ticks left until wake up, which required decrementing of the count for
each thread every time the timer interrupt is called.

The amount of time spent in the timer interrupt was minimized by recording
the tick to wake up instead of ticks left. With this change - and the 
sorted list - the timer interrupt only has to check the front of wait_semas 
if no thread is available to wake up. If N threads are ready, the
frontmost N threads can be popped out of the list and woken up.
***************************************************************************

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

***************************************************************************
As the description for the global lock wait_semas_lock presents, the lock
is used to lock the access to the global semaphore list, wait_semas.

When multiple threads call timer_sleep() simultaneously, only a single
thread acquires wait_semas_lock each time it inserts its sleep_sema_elem
into wait_semas list. Since the semaphores are inserted in order a single
element at a time, the threads are always woken up in the correct order.

Thus the race condition is resolved.
***************************************************************************

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

***************************************************************************
Race condition occurs when access to the list of sleeping threads, 
wait_semas, is not controlled properly. In our design, the frontmost
element of wait_semas list is checked each time the timer interrupt occurs
and if the first N thread's sleep time have expired, it wakes the threads 
by upping the corresponding semaphore and removing the element from 
wait_semas list. 

We use lock_try_acquire to limit the access to wait_semas list for cases 
where the timer interrupt is called within the critical section we have 
locked inside timer_sleep (), i.e. where the sleep_sema_elem is inserted
into wait_semas list. If lock_try_acquire () fails, it skips checking and
accessing the wait_semas, thus preserving the previous state of the list.

Hence, race condition does not occur from this scenario.
***************************************************************************

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

***************************************************************************
As discussed in Question A3, our initial design recorded remaining ticks 
to wake-up instead of wake-up-tick. The current design is much better than
previous because it reduces the number of instructions the timer interrupt
has to handle tremendously, from linear to a constant. 

The list of threads put to sleep, wait_semas, could have been replaced by 
a more efficient data structure such as a heap since the OS involves
insertion in order which takes O(log N) time. However, because we were 
provided with linked list structure which is much more reliable than
the code we may have produced, we chose safety over efficiency for
data structure.
***************************************************************************


             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Semaphore: semaphore has a list of waiters that are threads in its 
data structure. As semaphore's value comes down to zero and threads
that reach the semaphore waits for "sema_up"s we add each thread
as they reach the semaphore's "sema_down" to the list of waiters
using the function "list_insert_ordered" provided with our 
comparison function that compares the priorities of the threads.
We have stipulated in the comparison function so that threads 
of higher priority will occur in the front of the waiters list and 
so that when some other thread "sema_up"s this semaphore, our 
usage of "list_pop_front" function will effectively wake up the 
thread of the highest priority in the waiters list.

Lock: lock is basically a semaphore with the value of 1. Hence, the 
lock data structure contains a semaphore and this semaphore will 
have a list of threads that are waiting for the next "sema_up". 
Again, threads that reach the semaphore of the lock when the
semaphore's value is zero is added to the list of threads (waiters)
with the function "list_insert_ordered" with the comparison function
that compares priorities of threads. Upon a "sema_up" the thread
at the very front of the list will be woken up by the function 
"list_pop_front" and "thread_unblock". 

Note: however, we cannot ensure the "sortedness" of the waiters list
when priority donation is active. Therefore, we have arranged it so
that the list of waiters is sorted just before the "list_pop_front"
function is called to fetch the thread with the highest priority in 
waiters' list. The issue of synchronization comes into attention here
because after the list is sorted through "list_sort" the CPU can 
switch context and other priority donations might happen that involves
threads within the waiters' list. Hence, we made sure that the 
interrupts are turned off during the "list_sort", "list_pop_front", 
and "thread_unblock" process so that they are transactional. 

Condition variable: 
 
>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

We have noted in the assignment descriptions that we only have to 
deal with priority donations regarding locks.

The current thread will first have to pass through three ASSERT 
statements and "sema_down" the acquire_semaphore in the lock 
structure. Acquire_semaphore is a synchronization measure we have 
added to the lock data structure so that priority donations that 
propagate from this lock happens atomically. This will ensure that 
donation of priorities happen in a synchronized manner. Then the 
current thread will go into the function "lock_propagate_donation" and 
donate priority to the holder of this lock, say lock A, if it has 
higher priority than the holder of this lock. 

If the holder lock A is also blocked by some other lock, say lock B, 
and if priority of the holder of lock A is higher than 
that of holder of lock B, priority is donated from the holder of lock A
to the holder of lock B. The same process will happen recursively 
until the holder of a lock down the chain is in a blocked status. 
This recursive process handles nested priority donation well.   

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

We have added three new variables to the data structures of thread
and lock so that a lock knows which thread is holding it, a thread
has a list of locks that it has acquired, and a thread remembers the
original priority it had before any priority donations happened.

When lock_release is called by the current thread, we first set the
holder of this lock to NULL and remove this lock from the list of 
locks acquired by the current thread. Then by iterating through the
list of locks still acquired by the current thread, we determine 
the consequent priority value for the current thread after release 
of this lock. This process is to make sure that since priorities could
have been donated by waiters of other locks that the current thread 
holds, even after the current thread releases this lock, it cannot 
return straight to the original priority (before any donations) it had
but it has to return to the highest priority donated by waiters of 
other locks it holds. 

After priority value has been determined, we call "sema_up" function 
for this lock's semaphore, which will first disable interrupts, sort 
the list of waiters so that the waiter with the highest priority will 
be at the very front of the list, call "list_pop_front" to fetch the 
thread with highest priority, and then unblock the thread. At this 
moment, the CPU is likely to switch context to the thread just unblocked.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

There indeed exists a potential race in the "thread_set_priority".
Our version of "thread_set_priority" contains an if-statement that
sets the actual priority to new_priority (argument of the function)
only if new_priority is higher than the current actual priority of the
current thread. The CPU can switch context right at the moment when 
thread A passes the test conditions of the if-statement (line 551) 
and enters the if-statement body but has not executed any statements.
Then, the thread to which the CPU has changed context, say thread B, 
can donate priority to thread A and then change context back to 
thread A. Then, the conditions of the if-statement does not hold any 
more but we have already entered the body of the if-statement with 
thread A. Thread A's actual priority might be higher than the 
new_priority but it is still set to the new_priority where it should 
not have. Therefore, we can see that such race condition can 
perturb the priorities of threads if "thread_set_priority" is not 
synchronized. 

We believe that a lock cannot be used to synchronize "thread_set_
priority" because it could lead to a deadlock situation. If we create
a lock for priority values of a thread in order to avoid above race
condition, we can find ourselves in the below undesirable situation.
Thread A calls "thread_set_priority" and acquires the lock for 
its priority values. In the middle of the function, CPU switches context
to thread B, a thread with higher priority. Thread B is blocked by some 
other lock that thread A holds and tries to donate priority to thread A
but it is blocked again by the lock for thread A's priority values.
Priority donation cannot happen and many other threads exist in 
the system so CPU does not switch to thread A quickly. We find ourselves
in a deadlock situation. 

Our solution to this problem is disabling interrupts when we enter
"thread_set_priority" and returning it to old level when we exit. 
This way, CPU cannot switch context until the "thread_set_priority"
function finishes.  

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We considered other designs in the process of implementing priority
scheduling. However, we chose this design because of several reasons.


              ADVANCED SCHEDULER
              ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
Testing
